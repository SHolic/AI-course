{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# COSC-4117: Hidden Markov Model\n",
        "\n",
        "#1. Simple Markov Model\n",
        "In this example, we'll use a basic Markov chain with a small number of states and demonstrate how the state probabilities evolve over time: the convergence of probabilities in a Markov model as the number of time steps approaches infinity.\n",
        "\n",
        "A Markov model is a stochastic model used to model randomly changing systems where it is assumed that future states depend only on the current state, not on the sequence of events that preceded it. This **memoryless** property is known as the Markov property."
      ],
      "metadata": {
        "id": "QDHVlff3GalW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39g9SAQLGEF7",
        "outputId": "7359362a-b130-408e-c9f6-2d539a0f923c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: array([0.45, 0.05]),\n",
              " 2: array([0.42, 0.08]),\n",
              " 5: array([0.38472, 0.11528]),\n",
              " 10: array([0.37575583, 0.12424417]),\n",
              " 20: array([0.37500457, 0.12499543]),\n",
              " 50: array([0.375, 0.125]),\n",
              " 100: array([0.375, 0.125]),\n",
              " 500: array([0.375, 0.125]),\n",
              " 1000: array([0.375, 0.125])}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a simple transition matrix for a Markov chain\n",
        "# This should be a square matrix where each row sums up to 1\n",
        "transition_matrix = np.array([\n",
        "    [0.9, 0.1],  # Probabilities of moving from state 0 (Sun) to state 0 and 1 (Rain)\n",
        "    [0.3, 0.7]   # Probabilities of moving from state 1 to state 0 and 1\n",
        "])\n",
        "\n",
        "# Initial state probabilities\n",
        "initial_state = np.array([0.5, 0.0])  # Starting in state 0 with probability 1\n",
        "\n",
        "# Function to simulate the Markov chain\n",
        "def simulate_markov_chain(transition_matrix, initial_state, steps):\n",
        "    current_state = initial_state\n",
        "    for _ in range(steps):\n",
        "        current_state = np.dot(current_state, transition_matrix)\n",
        "    return current_state\n",
        "\n",
        "# Simulate the Markov chain for different time steps to observe convergence\n",
        "time_steps = [1, 2, 5, 10, 20, 50, 100, 500, 1000]\n",
        "results = {step: simulate_markov_chain(transition_matrix, initial_state, step) for step in time_steps}\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, as the number of steps increases, the state probabilities converge to approximately 0.75 for State 0 (Sun) and 0.25 for State 1 (Rain). This convergence demonstrates the property of Markov chains where, given enough time, the system reaches a steady state where the probabilities of being in each state remain constant. This steady state is independent of the initial state probabilities"
      ],
      "metadata": {
        "id": "-cmsK8zhJqmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Hidden Markov Model\n",
        "\n",
        "Here's the code for simulating belief states in a Hidden Markov Model, given a series of observations (Umbrella or No Umbrella).\n",
        "\n",
        "In this simulation:\n",
        "\n",
        "The belief states are updated at each step based on the observed data and the HMM parameters (transition and emission matrices).\n",
        "The update_belief_state function calculates the new belief state for each observation using the forward algorithm.\n",
        "The initial state probabilities are set to [0.5, 0.5], indicating an equal likelihood of starting in either state.\n",
        "When you run this code with the example observations, it outputs the probability distribution over the states at each step, reflecting the evolving belief about the system's state given the observations."
      ],
      "metadata": {
        "id": "WzWHrsFtxAPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Transition matrix for the Markov chain\n",
        "transition_matrix = np.array([\n",
        "    [0.7, 0.3],  # Probabilities of moving from state 0 (Rain) to state 0 and 1 (Sun)\n",
        "    [0.3, 0.7]   # Probabilities of moving from state 1 to state 0 and 1\n",
        "])\n",
        "\n",
        "# Emission matrix for the Hidden Markov Model (HMM)\n",
        "# Each row corresponds to a state and each column to an observation\n",
        "emission_matrix = np.array([\n",
        "    [0.9, 0.1],  # Probabilities of emitting 0 (Umbrella) or 1 (No umbrella) from state 0\n",
        "    [0.2, 0.8]   # Probabilities of emitting 0 or 1 from state 1\n",
        "])\n",
        "\n",
        "# Initial state probabilities\n",
        "initial_state = np.array([0.5, 0.5])  # Equally likely to start in either state\n",
        "\n",
        "def update_belief_state(belief_state, observation, transition_matrix, emission_matrix):\n",
        "    \"\"\"\n",
        "    Update the belief state based on an observation, using the forward algorithm.\n",
        "    \"\"\"\n",
        "    num_states = len(belief_state)\n",
        "    new_belief_state = np.zeros(num_states)\n",
        "\n",
        "    for state in range(num_states):\n",
        "        # Sum over all possible previous states\n",
        "        total = sum(belief_state[prev_state] * transition_matrix[prev_state, state]\n",
        "                    for prev_state in range(num_states))\n",
        "        new_belief_state[state] = total * emission_matrix[state, observation]\n",
        "\n",
        "    # Normalize the new belief state\n",
        "    new_belief_state /= np.sum(new_belief_state)\n",
        "    return new_belief_state\n",
        "\n",
        "def simulate_belief_states(transition_matrix, emission_matrix, initial_state, observations):\n",
        "    \"\"\"\n",
        "    Simulate the belief states for a series of observations.\n",
        "    \"\"\"\n",
        "    belief_states = [initial_state]\n",
        "    current_belief_state = initial_state\n",
        "\n",
        "    for observation in observations:\n",
        "        current_belief_state = update_belief_state(current_belief_state, observation,\n",
        "                                                   transition_matrix, emission_matrix)\n",
        "        belief_states.append(current_belief_state)\n",
        "\n",
        "    return belief_states\n",
        "\n",
        "# Example observations 0 (Umbrella) or 1 (No umbrella)\n",
        "example_observations = [0, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n",
        "\n",
        "# Simulate the belief states for the given observations\n",
        "belief_states = simulate_belief_states(transition_matrix, emission_matrix, initial_state, example_observations)\n",
        "\n",
        "# Output the belief states\n",
        "for step, belief in enumerate(belief_states):\n",
        "    print(f\"Step {step}: State 0 probability = {belief[0]:.4f}, State 1 probability = {belief[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rM3znlTEw_NB",
        "outputId": "8b7fa591-a3e6-4a24-f9c6-b2d54207454d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0: State 0 probability = 0.5000, State 1 probability = 0.5000\n",
            "Step 1: State 0 probability = 0.8182, State 1 probability = 0.1818\n",
            "Step 2: State 0 probability = 0.8834, State 1 probability = 0.1166\n",
            "Step 3: State 0 probability = 0.8945, State 1 probability = 0.1055\n",
            "Step 4: State 0 probability = 0.1937, State 1 probability = 0.8063\n",
            "Step 5: State 0 probability = 0.0705, State 1 probability = 0.9295\n",
            "Step 6: State 0 probability = 0.0575, State 1 probability = 0.9425\n",
            "Step 7: State 0 probability = 0.0563, State 1 probability = 0.9437\n",
            "Step 8: State 0 probability = 0.0562, State 1 probability = 0.9438\n",
            "Step 9: State 0 probability = 0.0562, State 1 probability = 0.9438\n",
            "Step 10: State 0 probability = 0.6817, State 1 probability = 0.3183\n"
          ]
        }
      ]
    }
  ]
}